# Text Preprocessing

## 1. 토큰화 (Tokenizaton)

주어진 코퍼스(corpus)에서 토큰(token)(보통 의미있는 단위)이라 불리는 단위로 나누는 작업

## 2. 정제 (Normalization)

용도에 맞게 데이터를 정제하는 작업

## 3. 어간추출 & 표제어 추출 (Stemming & Leematization)

하나의 단어로 일반화시켜서 문서 내의 단어 수를 줄이는 작업

## 4. 불용어 (Stopword)

갖고 있는 데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 큰 의미가 없는 단어 토큰을 제거하는 작업
불용어 = 자주 등장하지만 문장을 분석하는 데 있어서는 큰 도움이 되지 않는 단어

## 5. 정규 표현식 (Regular Expression)

특정한 규칙을 가진 문자열의 집합을 표현하는 데 사용하는 형식 언어

## 6. 단어 분리 (Subword Segmentation)

하나의 단어는 의미있는 여러 단어들의 조합으로 구성된 경우가 많기 때문에, 단어를 여러 단어로 분리하는 작업