# Tokenizaton

주어진 코퍼스에서 토큰이라 불리는 단위로 나누는 작업을 토큰화라고 부릅니다. 토큰의 단위가 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의합니다.

## 1. 단어 토큰화 (Word Tokenization)

토큰의 기준을 단어(Word)로 하는 경우 (단어 단위 외에도 단어구, 의미를 갖는 문자열로도 간주)

ex) Input : Time is an illusion. Lunchtime double so! (구두점)

    Output : "Time", "is", "an", "illustion", "Lunchtime", "double", "so"

1. 토큰화 중 생기는 선택의 순간

    원하는 결과가 나오도록 토큰화 도구를 직접 설계할 수도 있겠지만, 기존에 공개된 도구들을 사용하였을 때의 결과가 사용자의 목적과 일치한다면 해당 도구를 사용할 수도 있다.

    ex) test1.py, test2.py

2. 토큰화에서 고려해야할 상황

    1. 구두점이나 특수 문자를 단순 제외해서는 안 된다

        ex) 온점(.), 단어 자체의 구두점(Ph.D), 특수문자($10), 숫자 사이에 컴마(123,000)

    2. 줄임말과 단어 내에 띄어쓰기가 있는 경우

        ex) New York, rock 'n' roll

    3. 표준 토큰화 예제

        ex) test3.py

## 2. 문장 토큰화 (Sentence Tokenizatoin)

토큰의 단위가 문장(Sentence)인 경우

주의) 단순히 온점(.)으로 문장을 구분짓는다고 가정하면, 문장의 끝이 나오기 전에 이미 온점이 여러번 등장하여 예상한 결과가 나오지 않게 되는 경우가 있다.

ex) I'm actively looking for Ph.D. students, I get the same question a dozen times every year.

그렇기 때문에 사용하는 코퍼스가 어떤 국적의 언어인지, 또는 해당 코퍼스 내에서 특수문자들이 어떻게 사용되고 있는지에 따라서 직접 규칙들을 정의해볼 수 있다.

ex) test4.py

## 3. 이진 분류기 (Binary Classifier)

문장 토큰화에서의 예외 사항을 발생시키는 온점의 처리를 위해서 입력에 따라 두 개의 클래스로 분류하는 이진 분류기(binary classifier)를 사용하기도 합니다.

여기서 말하는 두 개의 클래스는

1. 온점(.)이 단어의 일부분일 경우. 즉, 온점이 약어(abbreivation)로 쓰이는 경우

2. 온점(.)이 정말로 문장의 구분자(boundary)일 경우를 의미할 것입니다.

## 4. 한국어 토큰화

1. 한국어는 교착어

2. 한국어는 띄어쓰기가 영어보다 잘 지켜지지 않는다.

이러한 이유 때문에 영어는 단어(어절) 토근화를 사용하고 한국어는 형태소 토큰화를 사용한다.

## 5. 품사 태깅(Part-of-speech tagging)

단어의 의미를 제대로 파악하기 위해서는 해당 단어가 어떤 품사로 쓰였는지 보는 것이 주요 지표가 될 수도 있습니다. 그에 따라 단어 토큰화 과정에서 각 단어가 어떤 품사로 쓰였는지를 구분해놓는 과정

NLTK와 KoNLPy 사용한다.

ex) test5.py
