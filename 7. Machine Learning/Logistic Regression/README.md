# Logistic Regression

두 개의 선택지 중에서 정답을 고르는 이진 분류를 해결 하기 위해 사용되는 대표적인 알고리즘

## 1. 이진 분류(Binary Classification)

x와 y의 관계를 표현하기 위해서는 직선을 표현하는 함수가 아니라 S자 형태

## 2. 시그모이드 함수(Sigmoid function)

0과 1사이의 값을 가지면서, S자 형태로 그려지는 이러한 조건을 충족하는 유명한 함수가 존재하는데, 바로 시그모이드 함수(Sigmoid function)이다.

H(X) = 1 / ( 1 + e<sup>−(Wx+b)</sup> ) = sigmoid(Wx + b) = σ(Wx+b)

ex) test1.py, test2.py(W의 변화), test3.py(b의 변화)

## 3. 비용 함수(Cost function)

로지스틱 회귀 또한 경사 하강법을 사용하여 가중치 W를 찾아내지만, 비용 함수로는 평균 제곱 오차를 사용하지 않는다. 로지스틱 회귀에서 평균 제곱 오차를 비용 함수로 사용하면, 경사 하강법을 사용하였을때 자칫 잘못하면 찾고자 하는 최소값이 아닌 잘못된 최소값에 빠진다.

로지스틱 회귀에서 찾아낸 비용 함수를 크로스 엔트로피(Cross Entropy)함수라고 한다. 즉, 결론적으로 로지스틱 회귀는 비용 함수로 크로스 엔트로피 함수를 사용하며, 가중치를 찾기 위해서 크로스 엔트로피 함수의 평균을 취한 함수를 사용한다.

ex) test4.py

## 4. 다중 로지스틱 회귀

H(X) = sigmoid(W<sub>1x1</sub>+W<sub>2x2</sub>+b)

ex) test5.py
